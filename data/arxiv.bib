@misc{bootstrap,
      title={Bootstrapping Statistical Inference for Off-Policy Evaluation}, 
      author={Botao Hao and Xiang Ji and Yaqi Duan and Hao Lu and Csaba Szepesv√°ri and Mengdi Wang},
      year={2021},
      eprint={2102.03607},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016},
  organization={PMLR}
}

@book{empirical_process,
  title={Weak convergence and empirical processes: with applications to statistics},
  author={Van Der Vaart, Aad W and van der Vaart, Aad and van der Vaart, Adrianus Willem and Wellner, Jon},
  year={1996},
  publisher={Springer Science \& Business Media}
}

@book{van,
  title={Asymptotic statistics},
  author={Van der Vaart, Aad W},
  volume={3},
  year={2000},
  publisher={Cambridge university press}
}

@book{kosorok,
  title={Introduction to empirical processes and semiparametric inference.},
  author={Kosorok, Michael R},
  year={2008},
  publisher={Springer}
}

@article{fei2021exponential,
  title={Exponential Bellman Equation and Improved Regret Bounds for Risk-Sensitive Reinforcement Learning},
  author={Fei, Yingjie and Yang, Zhuoran and Chen, Yudong and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2111.03947},
  year={2021}
}

@article{cristea2007global,
  title={A note on global implicit function theorem},
  author={Cristea, Mihai},
  journal={J. Inequal. Pure Appl. Math},
  volume={8},
  number={4},
  year={2007}
}

@inproceedings{hao2021sparse,
  title={Sparse feature selection makes batch reinforcement learning more sample efficient},
  author={Hao, Botao and Duan, Yaqi and Lattimore, Tor and Szepesv{\'a}ri, Csaba and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={4063--4073},
  year={2021},
  organization={PMLR}
}

@inproceedings{le2019batch,
  title={Batch policy learning under constraints},
  author={Le, Hoang and Voloshin, Cameron and Yue, Yisong},
  booktitle={International Conference on Machine Learning},
  pages={3703--3712},
  year={2019},
  organization={PMLR}
}

@article{kallus2020double,
  title={Double Reinforcement Learning for Efficient Off-Policy Evaluation in Markov Decision Processes.},
  author={Kallus, Nathan and Uehara, Masatoshi},
  journal={J. Mach. Learn. Res.},
  volume={21},
  pages={167--1},
  year={2020}
}

@inproceedings{yin2021near,
  title={Near-Optimal Provable Uniform Convergence in Offline Policy Evaluation for Reinforcement Learning},
  author={Yin, Ming and Bai, Yu and Wang, Yu-Xiang},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1567--1575},
  year={2021},
  organization={PMLR}
}

@inproceedings{szepesvari2005finite,
  title={Finite time bounds for sampling based fitted value iteration},
  author={Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={880--887},
  year={2005}
}

@inproceedings{uehara2020minimax,
  title={Minimax weight and q-function learning for off-policy evaluation},
  author={Uehara, Masatoshi and Huang, Jiawei and Jiang, Nan},
  booktitle={International Conference on Machine Learning},
  pages={9659--9668},
  year={2020},
  organization={PMLR}
}

@article{munos2008finite,
  title={Finite-Time Bounds for Fitted Value Iteration.},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={5},
  year={2008}
}

@article{yang2020bridging,
  title={Bridging exploration and general function approximation in reinforcement learning: Provably efficient kernel and neural value iterations},
  author={Yang, Zhuoran and Jin, Chi and Wang, Zhaoran and Wang, Mengdi and Jordan, Michael I},
  journal={arXiv e-prints},
  pages={arXiv--2011},
  year={2020}
}

@inproceedings{duan2020minimax,
  title={Minimax-optimal off-policy evaluation with linear function approximation},
  author={Duan, Yaqi and Jia, Zeyu and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={2701--2709},
  year={2020},
  organization={PMLR}
}

@article{wang2020statistical,
  title={What are the Statistical Limits of Offline RL with Linear Function Approximation?},
  author={Wang, Ruosong and Foster, Dean P and Kakade, Sham M},
  journal={arXiv preprint arXiv:2010.11895},
  year={2020}
}

@article{JiangL15,
  author    = {Nan Jiang and
               Lihong Li},
  title     = {Doubly Robust Off-policy Evaluation for Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1511.03722},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.03722},
  eprinttype = {arXiv},
  eprint    = {1511.03722},
  timestamp = {Mon, 13 Aug 2018 16:46:42 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/JiangL15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{fonteneau2013batch,
  title={Batch mode reinforcement learning based on the synthesis of artificial trajectories},
  author={Fonteneau, Raphael and Murphy, Susan A and Wehenkel, Louis and Ernst, Damien},
  journal={Annals of operations research},
  volume={208},
  number={1},
  pages={383--416},
  year={2013},
  publisher={Springer}
}

@book{efron1982jackknife,
  title={The jackknife, the bootstrap and other resampling plans},
  author={Efron, Bradley},
  year={1982},
  publisher={SIAM}
}

@article{On_PG,
  author    = {Alekh Agarwal and
               Sham M. Kakade and
               Jason D. Lee and
               Gaurav Mahajan},
  title     = {Optimality and Approximation with Policy Gradient Methods in Markov
               Decision Processes},
  journal   = {CoRR},
  volume    = {abs/1908.00261},
  year      = {2019},
  url       = {http://arxiv.org/abs/1908.00261},
  eprinttype = {arXiv},
  eprint    = {1908.00261},
  timestamp = {Fri, 09 Aug 2019 12:15:56 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1908-00261.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout

@inproceedings{chen2019information,
  title={Information-theoretic considerations in batch reinforcement learning},
  author={Chen, Jinglin and Jiang, Nan},
  booktitle={International Conference on Machine Learning},
  pages={1042--1051},
  year={2019},
  organization={PMLR}
}

@article{lagoudakis2003LSPI,
  title={Least-squares policy iteration},
  author={Lagoudakis, Michail G and Parr, Ronald},
  journal={The Journal of Machine Learning Research},
  volume={4},
  pages={1107--1149},
  year={2003},
  publisher={JMLR. org}
}

@article{lazaric2012finite_sample_LSPI,
  title={Finite-sample analysis of least-squares policy iteration},
  author={Lazaric, Alessandro and Ghavamzadeh, Mohammad and Munos, R{\'e}mi},
  journal={Journal of Machine Learning Research},
  volume={13},
  pages={3041--3074},
  year={2012}
}

@article{precup2000eligibility,
  title={Eligibility traces for off-policy policy evaluation},
  author={Precup, Doina},
  journal={Computer Science Department Faculty Publication Series},
  pages={80},
  year={2000}
}

@inproceedings{jiang2016doubly,
  title={Doubly robust off-policy value evaluation for reinforcement learning},
  author={Jiang, Nan and Li, Lihong},
  booktitle={International Conference on Machine Learning},
  pages={652--661},
  year={2016},
  organization={PMLR}
}

@inproceedings{yin2020asymptotically,
  title={Asymptotically efficient off-policy evaluation for tabular reinforcement learning},
  author={Yin, Ming and Wang, Yu-Xiang},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3948--3958},
  year={2020},
  organization={PMLR}
}

@inproceedings{thomas2016data,
  title={Data-efficient off-policy policy evaluation for reinforcement learning},
  author={Thomas, Philip and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={2139--2148},
  year={2016},
  organization={PMLR}
}

@article{xie2019towards,
  title={Towards optimal off-policy evaluation for reinforcement learning with marginalized importance sampling},
  author={Xie, Tengyang and Ma, Yifei and Wang, Yu-Xiang},
  journal={arXiv preprint arXiv:1906.03393},
  year={2019}
}

@inproceedings{li2015toward,
  title={Toward minimax off-policy value estimation},
  author={Li, Lihong and Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  booktitle={Artificial Intelligence and Statistics},
  pages={608--616},
  year={2015},
  organization={PMLR}
}

@article{min2021variance,
  title={Variance-Aware Off-Policy Evaluation with Linear Function Approximation},
  author={Min, Yifei and Wang, Tianhao and Zhou, Dongruo and Gu, Quanquan},
  journal={arXiv preprint arXiv:2106.11960},
  year={2021}
}

@article{wang2020reinforcement,
  title={Reinforcement learning with general value function approximation: Provably efficient approach via bounded eluder dimension},
  author={Wang, Ruosong and Salakhutdinov, Ruslan and Yang, Lin F},
  journal={arXiv preprint arXiv:2005.10804},
  year={2020}
}

@article{kostrikov2020statistical,
  title={Statistical bootstrapping for uncertainty estimation in off-policy evaluation},
  author={Kostrikov, Ilya and Nachum, Ofir},
  journal={arXiv preprint arXiv:2007.13609},
  year={2020}
}

@article{rubin1981bayesian,
  title={The bayesian bootstrap},
  author={Rubin, Donald B},
  journal={The annals of statistics},
  pages={130--134},
  year={1981},
  publisher={JSTOR}
}

@article{duan2021optimal,
  title={Optimal policy evaluation using kernel-based temporal difference methods},
  author={Duan, Yaqi and Wang, Mengdi and Wainwright, Martin J},
  journal={arXiv preprint arXiv:2109.12002},
  year={2021}
}

@article{long2020neuralnetwork,
  author    = {Jihao Long and
               Jiequn Han and
               Weinan E},
  title     = {An L\({}^{\mbox{2}}\) Analysis of Reinforcement Learning in High Dimensions
               with Kernel and Neural Network Approximation},
  journal   = {CoRR},
  volume    = {abs/2104.07794},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.07794},
  eprinttype = {arXiv},
  eprint    = {2104.07794},
  timestamp = {Mon, 19 Apr 2021 16:45:47 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-07794.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{nguyentang2021sample,
      title={Sample Complexity of Offline Reinforcement Learning with Deep ReLU Networks}, 
      author={Thanh Nguyen-Tang and Sunil Gupta and Hung Tran-The and Svetha Venkatesh},
      year={2021},
      eprint={2103.06671},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{fan2020theoretical,
      title={A Theoretical Analysis of Deep Q-Learning}, 
      author={Jianqing Fan and Zhaoran Wang and Yuchen Xie and Zhuoran Yang},
      year={2020},
      eprint={1901.00137},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{farahmand2016regularized,
  title={Regularized policy iteration with nonparametric function spaces},
  author={Farahmand, Amir-massoud and Ghavamzadeh, Mohammad and Szepesv{\'a}ri, Csaba and Mannor, Shie},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={4809--4874},
  year={2016},
  publisher={JMLR. org}
}

@article{ormoneit2002kernel,
  title={Kernel-based reinforcement learning},
  author={Ormoneit, Dirk and Sen, {\'S}aunak},
  journal={Machine learning},
  volume={49},
  number={2},
  pages={161--178},
  year={2002},
  publisher={Springer}
}

@misc{chen2022wellposedness,
      title={On Well-posedness and Minimax Optimal Rates of Nonparametric Q-function Estimation in Off-policy Evaluation}, 
      author={Xiaohong Chen and Zhengling Qi},
      year={2022},
      eprint={2201.06169},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}

@misc{uehara2021finite,
      title={Finite Sample Analysis of Minimax Offline Reinforcement Learning: Completeness, Fast Rates and First-Order Efficiency}, 
      author={Masatoshi Uehara and Masaaki Imaizumi and Nan Jiang and Nathan Kallus and Wen Sun and Tengyang Xie},
      year={2021},
      eprint={2102.02981},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{shi2021statistical,
      title={Statistical Inference of the Value Function for Reinforcement Learning in Infinite Horizon Settings}, 
      author={C. Shi and S. Zhang and W. Lu and R. Song},
      year={2021},
      eprint={2001.04515},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{jin2019provably,
      title={Provably Efficient Reinforcement Learning with Linear Function Approximation}, 
      author={Chi Jin and Zhuoran Yang and Zhaoran Wang and Michael I. Jordan},
      year={2019},
      eprint={1907.05388},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{cai2020provably,
  title={Provably efficient exploration in policy optimization},
  author={Cai, Qi and Yang, Zhuoran and Jin, Chi and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={1283--1294},
  year={2020},
  organization={PMLR}
}

@article{wang2019optimism,
  title={Optimism in reinforcement learning with generalized linear function approximation},
  author={Wang, Yining and Wang, Ruosong and Du, Simon S and Krishnamurthy, Akshay},
  journal={arXiv preprint arXiv:1912.04136},
  year={2019}
}

@inproceedings{zhou2021provably,
  title={Provably efficient reinforcement learning for discounted mdps with feature mapping},
  author={Zhou, Dongruo and He, Jiafan and Gu, Quanquan},
  booktitle={International Conference on Machine Learning},
  pages={12793--12802},
  year={2021},
  organization={PMLR}
}

@article{khamaru2020temporal,
  title={Is temporal difference learning optimal? an instance-dependent analysis},
  author={Khamaru, Koulik and Pananjady, Ashwin and Ruan, Feng and Wainwright, Martin J and Jordan, Michael I},
  journal={arXiv preprint arXiv:2003.07337},
  year={2020}
}

@misc{kallus2021efficiently,
      title={Efficiently Breaking the Curse of Horizon in Off-Policy Evaluation with Double Reinforcement Learning}, 
      author={Nathan Kallus and Masatoshi Uehara},
      year={2021},
      eprint={1909.05850},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}